https://github.com/chvinodgcp5010/emartapp

https://code.visualstudio.com/download

microservice and how it is is very good in software development and delivering features to the users quickly and efficiently.

microservice architecture is here and it is going to stay for a very long time.
And being a DevOps, you will definitely witness micro service application and you should know first how to containerize it.

So,

Block diagram:
================

API Gateway (Nginx) -------------------> / -------------------> client(Angular)
                    ------------------->/api -----------------> emart api (nodejs) ------>mongo db
                    ------------------->/books --------------->books api (java) ---------> Mysql DB
                    
                    
We have four services here.

NGINX, which is the API gateway, which is the front end from where all the request comes. And all the communication between 
micrservices happen through this API gateway.This will be an nginx service which willlisten for the request and route based on
the headers, based on the URLs.

So if the request comes on a route, that is if you're just accessing the URL, then it sends to
the "client" microservice which is written in "angular".So this loads the front end pages of the website.
And for back end data it is going to contact the API service "emart API" which is written in "NodeJs"
and the URL will be "/API" and NodeJS application.These APIs will need database.And here we are using MongoDB, a NoSQL database.


There is also one more integration of another service, "books" API.And this is written in "Java".It uses my SQL database, 
which is an SQL database and it's URLs WebAPI.So this is an ecommerce application which has multiple microservice.


Source code:
------------

https://github.com/chvinodgcp5010/emartapp


Here "client", which is the "angular application",
"java API", which is the "Books API".
And you have "NGINX", which is the "API gateway",
"node API" which is our "node JS microservice". 

Now, all the microservices source code is in one repository.

Repository name is "Emartapp" and these kinds of repositories are called as "mono repo".All the micro service source code is in one repository.Based on the requirement, it will be also segregated into multiple repositories.like you will have a separate repository for client, separate for Java API, separate for Node API and separate for NGINX.And that is very beneficial for creating separate CICD pipelines for all of this.

We will go through its docker file and its docker compose file.So if you do not have Visual Studio install it.
Or if you want to use any other ID like IntelliJ or anything else of your choice

First we will go to the "client".And here we have a file called "docker file".Click on that.


====================================== 1. client source code ==============================================

https://github.com/chvinodgcp5010/emartapp/blob/main/client/Dockerfile


FROM node:14 AS web-build
WORKDIR /usr/src/app
COPY ./ ./client
RUN cd client && npm install && npm run build --prod

# Use official nginx image as the base image
FROM nginx:latest
# Copy the build output to replace the default nginx contents.
COPY --from=web-build /usr/src/app/client/dist/client/ /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf

# Expose port 4200
EXPOSE 4200


========================================== EXPLANATION ==============================================

->This is a multi stage docker file.First stage is to build the artifact and second stage is to copy the artifact into our main image.

So first stage we are taking a 

->node node image.  Angular application will be built under node image. We give it name as  "web_build". The tag is 14. 
->We set a working directory. /USR/SRC/app 
->copy instruction is going to copy everything, which is all the source code of the client into /client directory.

->So basically your code will be in USR/SRC/app/client and then the run instruction which goes into the client directory and run the command "NPM install" .

And then it is going to run "NPM run build prod".


(((NOTE:)))
===========

If you have no idea about node and angular, do not worry.
You don't need to learn that. Keep in mind, whenever you get into project, you need to get information from the developer of the build 
process or the build commands to use to get the artifact.

That is what I do?
==================

I talk to the developers. I get the information.Because when you write a docker file, the docker file contains the build steps.
You should know how to build that application.

So from the source code you get the output.Now the artifact which will be in the client directory,

we need to copy to in our main image. Now, "Angular application" will be hosted on "NGINX" .Yes, it's a "web application".
It's a web app. So we are using here NGINX. So we fetch an NGINX image.We copy from web build which is from here.

From this image we copy copy what?

We copy this directory.So USR/SRC/app/client/dist

This is the path from this "build_image".In "dist" you have a "/client" directory and the content of that or that will be copied into this path "/usr/share/nginx/html".


NOTE:
=====
((Now you will see how will I know this path?

There is the artifact. This is the path where you will have the artifact that will be also getting or
you'll be getting that information from the developer.

=>So when you run the build command, there will be the artifact in this client and those HTML files you're going to put into the NGINX image at this path.

Why this path?

Because that's how the NGINX image was created. So if you read the official documentation of NGINX image on docker hub, you will see you need to place your HTML file in this directory.

https://github.com/nginxinc/docker-nginx/blob/04226fe92cc11bed68dae464eb60fd5399daf3b1/mainline/debian/Dockerfile

Also we are copying an NGINX configuration file into this path. So we need our own customized configuration.
So let's check that Nginx configuration file which is here.So this configuration file simply says if someone access
this nginx container on / path, then show the content from this directory and index.HTML and index.HTML files will be loaded in the browser.

So in your artifact you will have this file index.HTML which basically our Nginx container is presenting to the user.

================================================ 2. NODE API =============================================================

https://github.com/chvinodgcp5010/emartapp/blob/main/nodeapi/Dockerfile


FROM node:14 AS nodeapi-build
WORKDIR /usr/src/app
COPY ./ ./nodeapi/
RUN cd nodeapi && npm install

FROM node:14
WORKDIR /usr/src/app/
COPY --from=nodeapi-build /usr/src/app/nodeapi/ ./
RUN ls
EXPOSE 5000
CMD ["/bin/sh", "-c", "cd /usr/src/app/ && npm start"]
# Test3


================================================== EXPLANATION =======================================================

So you have this first stage which is going to "build the artifact" and the second stage which is going to use that artifact.
So similar process work directory we set up,

we copy the source code from current directory. So all the source code will be copied into Node API directory instruction.
Go into that directory and run NPM install. That's the build command.

The "first stage" will "generate the artifact". 
The "second stage" it is "running on node".

Again, we set the work directory and we copy the artifact from "Node-API" build which is from this image, from this path Node API directory which is there copied into the current directory.

COPY --from=nodeapi-build /usr/src/app/nodeapi/ ./

this will be the current directory work directory and just one LS command that I have given. So it's going to list the files from
that directory which you can see when you're building it, exposing it on port 5000.

And we are going to run this command to run our Node app, which is basically go into that directory and "run NPM start", which will start your Node app.


================================================ 3. JAVA API =============================================================

https://github.com/chvinodgcp5010/emartapp/blob/main/javaapi/Dockerfile

FROM openjdk:8 AS BUILD_IMAGE
WORKDIR /usr/src/app/
RUN apt update && apt install maven -y
COPY ./ /usr/src/app/
RUN mvn install -DskipTests

FROM openjdk:8
WORKDIR /usr/src/app/
COPY --from=BUILD_IMAGE /usr/src/app/target/book-work-0.0.1-SNAPSHOT.jar ./book-work-0.0.1.jar

EXPOSE 9000
ENTRYPOINT ["java","-jar","book-work-0.0.1.jar"]
# Test



=============================================== EXPLANATION ================================================================

This is written in Java as the docker file. Again, this is also multi stage.
We take an "open JDK image" because we need Maven.

->We set the work directory /usr/src/app, 
->we run "apt update" and "apt install maven", which installs maven.

We copy the source code to USR/SRC/app directory and we run the command  "MVN install" , which will build the artifact.
And this is where we will be hosting.

So again, open JDK eight web directory, copy the artifact which is at this path book work version "snapshot.Jar"
into the current directory with this name. Current directory means USR SRC app will be the current directory.

->Expose it on port 9000 and run the command Java Jar and the Jar file path which is going to run the Java application and expose it on port 9000.


================================================ 4. GATEWAY (NGINX) API =============================================================


https://github.com/chvinodgcp5010/emartapp/blob/main/nginx/default.conf

Here you have NGINX.  Now, we are not going to build a separate NGINX image. We're going to use official NGINX image.

This is for the "API gateway".

We just have the configuration here. So this configuration file "default.conf" we will copy to our Nginx official image.

Not copy exactly.

We'll attach it as a volume, this configuration file. 

->So we don't need to build a separate NGINX image, because all we need is thiS configuration for the NGINX container to load 
And the configuration is this, the routing rules, which is for our client container API, which is for our Node container and 
/web API, which is for our Java container which will be running Books API.
So this configuration has basically three routing rules for our three micro services.


RUN nginx container and all containers using below "compose" file

======================================== DOCKER COMPOSE ===========================================

https://github.com/chvinodgcp5010/emartapp/blob/main/docker-compose.yaml

version: "3.8"
services:
    client:
        build:
            context: ./client
        ports:
            - "4200:4200"
        container_name: client
        depends_on:
            [api, webapi]

    api:
        build:
            context: ./nodeapi
        ports:
            - "5000:5000"
        container_name: api
        depends_on:
            - nginx
        depends_on:
            [emongo]

    webapi:
        build:
            context: ./javaapi
        ports:
            - "9000:9000"
        restart: always
        container_name: webapi
        depends_on:
            [emartdb]

    nginx:
        restart: always
        image: nginx:latest
        container_name: nginx
        volumes:
            - "./nginx/default.conf:/etc/nginx/conf.d/default.conf"
        ports:
            - "80:80"
        command: ['nginx-debug', '-g', 'daemon off;']
        depends_on:
            [client]

    emongo:
       image: mongo:4
       container_name: emongo
       environment:
         - MONGO_INITDB_DATABASE=epoc
       ports:
         - "27017:27017"
    emartdb:
      image: mysql:5.7
      container_name: emartdb
      ports:
         - "3306:3306"
      environment:
        - MYSQL_ROOT_PASSWORD=emartdbpass     
        - MYSQL_DATABASE=books


================================================================


Docker compose.

Now, you have "four services", actually, and not only four services for microservices, they also have two databases.

And when you want to run all of them together or build them together, you need docker compose.
So "services" means "containers"

So we have "Client", which is again our "angular app" running in NGINX container which for that we have the docker file.

We have API, which is Node web API, which is our Java Books API.

And then Nginx, which is our API gateway. Plus we have the MongoDB service and emartdb, which is our MySQL service.


So the client container, you have a build instruction here. Context means where is your docker file path. ./client.
So if we see in the client, we have the docker file.So it's going to use this docker file to build this container container image map port 4200 with 4200 of container, container name. We have given client, which is important based on our routing rules.
And this container depends on API and web API container.That means first it will be building API web API.Then only it will build the client

container API, which is our Node. So build instruction goes to node API or node API directory where we have the docker file, which is here.This one there's the docker file port mapping container name we are giving API.And this depends on the NGINX container.

So NGINX container needs to start first.Before this also it depends on Mongo Emongo container.So those two containers should be running.Then only this API container will start.


Web API.

This is our Java application, the Books API.And it's in Java API directory, the docker file.So in Java API you have the docker
file port mapping container name web API.This depends on the emart DB,which is the MySQL database.
The database needs to be ready so Web API container can connect to it.

As I told you NGINX, we are not building a separate image.We are taking the NGINX official image from docker hub.
Container name is NGINX.But we are mapping the Nginx configuration file, which is the routing rules in the default
configuration of the container map port mapping at.And the command will be running nginx-debug -g daemon off
And this depends on the client container, which is our Node API.

Sorry, not API angular angular frontend.And then we have MongoDB database.This is for the Node API and it
is also running from the official Mongo image.Container name is Emongo And we need to set up the database name to Epoch.

And the database name is the project requirement.It is in the Node API configuration that it needs to connect to the database named Epoch.So that's why that name port mapping.And then finally emartdb, which is our MySQL container.And it is just a simple MySQL container port mapping.

And we need to set up the MySQL root password to emartdbpass and the database names to Books.Now, if you're interested, you can
go to the source code.


docker file and docker compose file and Nginx configuration.


=========================================
Let's just pull all of them now.So client docker file, java API docker File Nginx configuration file, node API docker file.
So when you are containerizing, you first need to create the docker file for your customized image.
So we have three docker file here once again and the Nginx configuration for our Nginx container, which is the API gateway.
Let me close these things. And finally the docker compose.

So containerizing in short, really means writing docker file and docker compose file and configuration.
Of course, if it is required in your microservices. Like here, we have the NGINX configuration file.
Now, I know in such short span of time, writing docker file is nearly impossible.

It's only possible if you already understand Node, Java and all those things. This will take some time.
When you work in a project, you need to work with the developer.

Understand the build steps and how to host your application. For example, Angular returns the
HTML files and HTML files.

We can run it on NGINX or Apache or any such service like that.

If it's Java, we can directly run it on JDK or Tomcat containers.If it's Node again know the build process and Node artifact.
We host it on the Node JS itself.It has its own hosting service.

If you already have experience with this,you will do it very quickly.

If you do not have experience with this,you need to work with the developers.Understand build processes and how
to host the artifact.Okay, two things while writing the docker file, know the build process and the hosting method.
Once you know that, your job will be writing docker file and then docker compose file
to run all of them together.

And this takes time. While you're doing this in real time in a project, you may get many errors while
you're building and running container, then docker compose.When you're running containers together, I have talked
about roubleshooting in the container section, checking logs,finding out what is the problem.

Simple problems like not able to connect to the database may be wrong username and password,or wrong database names, or the container name you have given wrong going through the configuration.

So when you're doing this, when you're writing it from the scratch, be patient.Take your time.Work with the developers.
Once again, containerizing is docker file.

Docker compose the next lecture.We will run all this together and it's going tobe very simple once you have all this ready.
So take your time.Go through the docker files,go through the compose file.Understand each and every option.




    nginx:
        restart: always
        image: nginx:latest
        container_name: nginx
        volumes:
            - "./nginx/default.conf:/etc/nginx/conf.d/default.conf"
        ports:
            - "80:80"
        command: ['nginx-debug', '-g', 'daemon off;']
        depends_on:
            [client]



Restart always.  Because if the DB container still does not come and it takes time, this container Web API container will fail.
If it fails, it's going to restart.And when it restarts, by the time the DB container should be running and it can connect to it.






